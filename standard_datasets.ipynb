{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba409a4f-6e35-4614-818f-f2272c3c157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7f3b2-7f98-424e-bc42-9480cc40f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1fdf5-56e6-4d06-aa96-cf692d333400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6316d860-a57a-49c6-8171-38c550ab3dbb",
   "metadata": {},
   "source": [
    "# Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54501dee-6254-44db-9937-868b4c06025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574c2b2-ce44-4403-9b55-889c67f73e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [{0:[X,y]}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd64bd5c-79eb-4b8c-91f3-fb1cbdb9afde",
   "metadata": {},
   "source": [
    "# California housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02940a94-1aa6-4cb4-87cd-7b86032f61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "all_data.append({0:[X.to_numpy(),y.to_numpy()]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38685a8-b33e-45e6-8beb-c91582a811bf",
   "metadata": {},
   "source": [
    "# Liver disorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49e30a-318f-4100-a288-57c2a4875361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "ld = fetch_openml(name='liver-disorders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c19aa-3f9a-476c-9d49-29ad4e8b70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = ld['data'].to_numpy(),ld['target'].to_numpy()\n",
    "all_data.append({0:[X,y]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393b553-2de8-4e45-9c6f-91985f24c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "dict_data = {}\n",
    "dict_data[\"Diabetes\"] = {}\n",
    "dict_data[\"California housing\"] = {}\n",
    "dict_data[\"Liver disorders\"] = {}\n",
    "\n",
    "for k in all_data[0]:\n",
    "    x01,x02,y01,y02 = train_test_split(all_data[0][k][0], all_data[0][k][1], test_size=0.3,random_state=42)\n",
    "    dict_data[\"Diabetes\"][k] = {\"train\":{\"X\":x01,\"y\":y01},\"test\":{\"X\":x02,\"y\":y02}}\n",
    "    \n",
    "for k in all_data[1]:\n",
    "    x11,x12,y11,y12 = train_test_split(all_data[1][k][0], all_data[1][k][1],test_size=0.3,random_state=42)\n",
    "    dict_data[\"California housing\"][k] = {\"train\":{\"X\":x11,\"y\":y11},\"test\":{\"X\":x12,\"y\":y12}} \n",
    "\n",
    "for k in all_data[2]:\n",
    "    x11,x12,y11,y12 = train_test_split(all_data[2][k][0], all_data[2][k][1],test_size=0.3,random_state=42)\n",
    "    dict_data[\"Liver disorders\"][k] = {\"train\":{\"X\":x11,\"y\":y11},\"test\":{\"X\":x12,\"y\":y12}} \n",
    "\n",
    "all_data = dict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06f10d-26fe-4c58-898b-dd6ce7965e95",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbd0f0-9e06-477e-9e59-2e86be3d3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from boosted_forest import CascadeBoostingRegressor\n",
    "from deepforest import CascadeForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "#xgb.set_config(verbosity=2)\n",
    "\n",
    "def make_modelXGB(max_depth,layers,C):\n",
    "    return xgb.XGBRegressor(max_depth = max_depth, n_estimators = layers)\n",
    "\n",
    "def make_modelCascade(max_depth,layers,C):\n",
    "    return CascadeForestRegressor(max_depth = max_depth, max_layers = layers, n_estimators=4)\n",
    "\n",
    "def make_modelBoosted(max_depth,layers,C):\n",
    "    return CascadeBoostingRegressor(C=C, n_layers=layers, n_estimators = 1, max_depth=max_depth, n_iter_no_change = 1, validation_fraction = 0.1, learning_rate = 0.9)\n",
    "\n",
    "\n",
    "models = {\"XGB\":make_modelXGB,\"Cascade Forest\":make_modelCascade, \"Boosted Forest\": make_modelBoosted}\n",
    "\n",
    "bo_data = []    \n",
    "\n",
    "for model_name in models:\n",
    "    make_model = models[model_name]\n",
    "    for ds_name in all_data:\n",
    "        for depth in all_data[ds_name]:\n",
    "            dat = all_data[ds_name][depth]\n",
    "            x_train = dat[\"train\"][\"X\"]\n",
    "            x_test = dat[\"test\"][\"X\"]\n",
    "            Y_train = dat[\"train\"][\"y\"].flatten()\n",
    "            Y_test = dat[\"test\"][\"y\"].flatten()            \n",
    "\n",
    "            def objective(trial):\n",
    "                layers = trial.suggest_int('layers', 5, 15)\n",
    "                max_depth = trial.suggest_int('max_depth', 1, 2)\n",
    "\n",
    "                if model_name == \"Boosted Forest\":\n",
    "                    C = trial.suggest_int('C', 1, 2000)\n",
    "                else:\n",
    "                    C = 0\n",
    "\n",
    "                kf = KFold(n_splits=3)\n",
    "                scores = []\n",
    "                for _, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "                    model = make_model(max_depth,layers,C)\n",
    "                    \n",
    "                    model.fit(\n",
    "                         x_train[train_index],\n",
    "                         Y_train[train_index],\n",
    "                    )\n",
    "                    y_pred = model.predict(x_train[test_index]) #, batch_size=batch_size)\n",
    "                    scores.append(mean_squared_error(Y_train[test_index].flatten(),y_pred.flatten()))\n",
    "                return np.asarray(scores).mean() \n",
    "            \n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(objective, n_trials=20)    \n",
    "            \n",
    "            layers = study.best_trial.params[\"layers\"]  \n",
    "            max_depth = study.best_trial.params[\"max_depth\"]  \n",
    "\n",
    "            if model_name == \"Boosted Forest\":\n",
    "                C = study.best_trial.params[\"C\"]  \n",
    "            else:\n",
    "                C = 0\n",
    "            model = make_model(max_depth,layers,C)\n",
    "            model.fit(\n",
    "                 x_train,\n",
    "                 Y_train,\n",
    "            )        \n",
    "            \n",
    "            y_pred = model.predict(x_test) #, batch_size=batch_size)\n",
    "            mse_score = mean_squared_error(Y_test.flatten(),y_pred.flatten())\n",
    "            mae_score = mean_absolute_error(Y_test.flatten(),y_pred.flatten())\n",
    "            print(model_name,ds_name,depth,mse_score, mae_score, Y_test.min(),Y_test.max())     \n",
    "            bo_data.append([model_name,ds_name,depth,mse_score, mae_score])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a6484-c8b1-45ad-a46b-3a44fd639fd4",
   "metadata": {},
   "source": [
    "# Alternative weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf1433-5a85-4345-8290-bc679d44b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from ecdfr.gcForest import gcForest\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "from boosted_forest import CascadeBoostingRegressor\n",
    "from deepforest import CascadeForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "#xgb.set_config(verbosity=2)\n",
    "\n",
    "def make_modelECDFR(max_depth,layers,resampling_rate, et):\n",
    "    config = {\"estimator_configs\":[{\"n_fold\": 5,\"type\":None,\"max_depth\":max_depth}],\n",
    "              \"error_threshold\": et,\n",
    "              \"resampling_rate\": resampling_rate,\n",
    "              \"random_state\":None,\n",
    "              \"max_layers\":layers,\n",
    "              \"early_stop_rounds\":1,\n",
    "              \"train_evaluation\":mean_squared_error}\n",
    "    \n",
    "    return gcForest(config,1)\n",
    "\n",
    "models = {\"ecdfr\":make_modelECDFR}\n",
    "\n",
    "bo_data = []    \n",
    "\n",
    "for model_name in models:\n",
    "    make_model = models[model_name]\n",
    "    for ds_name in all_data:\n",
    "        for depth in all_data[ds_name]:\n",
    "            dat = all_data[ds_name][depth]\n",
    "            x_train = dat[\"train\"][\"X\"]\n",
    "            x_test = dat[\"test\"][\"X\"]\n",
    "            Y_train = dat[\"train\"][\"y\"].flatten()\n",
    "            Y_test = dat[\"test\"][\"y\"].flatten()            \n",
    "\n",
    "            def objective(trial):\n",
    "                layers = trial.suggest_int('layers', 5, 15)\n",
    "                max_depth = trial.suggest_int('max_depth', 1, 2)\n",
    "\n",
    "                C = trial.suggest_float('resampling_rate', 1.1, 1.8)\n",
    "                et = trial.suggest_float('et', 0.01, 0.9)\n",
    "                \n",
    "                kf = KFold(n_splits=3)\n",
    "                scores = []\n",
    "                try:\n",
    "                    for _, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "                        model = make_modelECDFR(max_depth,layers,C,et)\n",
    "                    \n",
    "                        model.fit(\n",
    "                             x_train[train_index],\n",
    "                             Y_train[train_index],\n",
    "                        )\n",
    "                        y_pred = model.predict(x_train[test_index]) #, batch_size=batch_size)\n",
    "                        scores.append(mean_squared_error(Y_train[test_index].flatten(),y_pred.flatten()))\n",
    "                except:\n",
    "                    scores = [1000000000.]\n",
    "                return np.asarray(scores).mean() \n",
    "            \n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(objective, n_trials=1000)    \n",
    "            \n",
    "            layers = study.best_trial.params[\"layers\"]  \n",
    "            max_depth = study.best_trial.params[\"max_depth\"]  \n",
    "\n",
    "\n",
    "            C = study.best_trial.params[\"resampling_rate\"]  \n",
    "            et = study.best_trial.params[\"et\"]  \n",
    "            model = make_model(max_depth,layers,C,et)\n",
    "            model.fit(\n",
    "                 x_train,\n",
    "                 Y_train,\n",
    "            )        \n",
    "            \n",
    "            y_pred = model.predict(x_test) #, batch_size=batch_size)\n",
    "            mse_score = mean_squared_error(Y_test.flatten(),y_pred.flatten())\n",
    "            mae_score = mean_absolute_error(Y_test.flatten(),y_pred.flatten())\n",
    "            print(model_name,ds_name,depth,mse_score, mae_score, Y_test.min(),Y_test.max())     \n",
    "            bo_data.append([model_name,ds_name,depth,mse_score, mae_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589b187-466d-4640-b212-b80afb874abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from boosted_forest import CascadeBoostingRegressor\n",
    "from deepforest import CascadeForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "#xgb.set_config(verbosity=2)\n",
    "\n",
    "def make_modelCascade(max_depth,layers,C,wt):\n",
    "    wf = {0:\"linear\", 1:\"1-w^1/2\", 2:\"1-w2\"}\n",
    "    return CascadeForestRegressor(max_depth = max_depth, max_layers = layers, n_estimators=4,adaptive=True,weighting_function = wf[wt])\n",
    "\n",
    "\n",
    "models = {\"AWDF\":make_modelCascade}\n",
    "\n",
    "bo_data = []    \n",
    "\n",
    "for model_name in models:\n",
    "    make_model = models[model_name]\n",
    "    for ds_name in all_data:\n",
    "        for depth in all_data[ds_name]:\n",
    "            dat = all_data[ds_name][depth]\n",
    "            x_train = dat[\"train\"][\"X\"]\n",
    "            x_test = dat[\"test\"][\"X\"]\n",
    "            Y_train = dat[\"train\"][\"y\"].flatten()\n",
    "            Y_test = dat[\"test\"][\"y\"].flatten()            \n",
    "\n",
    "            def objective(trial):\n",
    "                layers = trial.suggest_int('layers', 5, 15)\n",
    "                max_depth = trial.suggest_int('max_depth', 1, 2)\n",
    "                wt = trial.suggest_int('weight_function', 0, 2)   \n",
    "                if model_name == \"Boosted Forest\":\n",
    "                    C = trial.suggest_int('C', 1, 2000)\n",
    "                else:\n",
    "                    C = 0\n",
    "\n",
    "                kf = KFold(n_splits=3)\n",
    "                scores = []\n",
    "                for _, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "                    model = make_model(max_depth,layers,C,wt)\n",
    "                    \n",
    "                    model.fit(\n",
    "                         x_train[train_index],\n",
    "                         Y_train[train_index],\n",
    "                    )\n",
    "                    y_pred = model.predict(x_train[test_index]) #, batch_size=batch_size)\n",
    "                    scores.append(mean_squared_error(Y_train[test_index].flatten(),y_pred.flatten()))\n",
    "                return np.asarray(scores).mean() \n",
    "            \n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(objective, n_trials=50)    \n",
    "            \n",
    "            layers = study.best_trial.params[\"layers\"]  \n",
    "            max_depth = study.best_trial.params[\"max_depth\"]  \n",
    "            wt = study.best_trial.params['weight_function']\n",
    "            if model_name == \"Boosted Forest\":\n",
    "                C = study.best_trial.params[\"C\"]  \n",
    "            else:\n",
    "                C = 0\n",
    "            model = make_model(max_depth,layers,C,wt)\n",
    "            model.fit(\n",
    "                 x_train,\n",
    "                 Y_train,\n",
    "            )        \n",
    "            \n",
    "            y_pred = model.predict(x_test) #, batch_size=batch_size)\n",
    "            mse_score = mean_squared_error(Y_test.flatten(),y_pred.flatten())\n",
    "            mae_score = mean_absolute_error(Y_test.flatten(),y_pred.flatten())\n",
    "            print(model_name,ds_name,depth,mse_score, mae_score, Y_test.min(),Y_test.max())     \n",
    "            bo_data.append([model_name,ds_name,depth,mse_score, mae_score])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d598c-6512-4aa4-964b-b562d1998be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
