{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabeb036-bea1-418a-a5f6-5b4a862c0a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_416423/2105005005.py:25: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv('cup98LRN.txt')\n",
      "/tmp/ipykernel_416423/2105005005.py:27: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_eval = pd.read_csv('cup98VAL.txt')\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/tmp/ipykernel_416423/2105005005.py:62: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  value_counts = pd.value_counts(y)\n",
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss             Time \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from os.path import join\n",
    "def printf(*args, fname=\"log.txt\"):\n",
    "    with open(join(\"test_outputs\",fname),\"a+\") as f:\n",
    "        for a in args:\n",
    "            f.write(str(a) + \" \")\n",
    "        f.write(\"\\n\") \n",
    "    print(args) \n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "all_data = []\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('cup98LRN.txt')\n",
    "num_train = df_train.shape[0]\n",
    "df_eval = pd.read_csv('cup98VAL.txt')\n",
    "df_eval_target = pd.read_csv('lifetime-value/kdd_cup_98/valtargt.txt')\n",
    "df_eval = df_eval.merge(df_eval_target, on='CONTROLN')\n",
    "\n",
    "# Original: https://github.com/google/lifetime_value/blob/master/notebooks/kdd_cup_98/regression.ipynb\n",
    "df = pd.concat([df_train, df_eval], axis=0, sort=True)\n",
    "y = df['TARGET_D'][:num_train]\n",
    "\n",
    "VOCAB_FEATURES = [\n",
    "    'ODATEDW',  # date of donor's first gift (YYMM)\n",
    "    'OSOURCE',  # donor acquisition mailing list\n",
    "    'TCODE',    # donor title code\n",
    "    'STATE',\n",
    "    'ZIP',\n",
    "    'DOMAIN',   # urbanicity level and socio-economic status of the neighborhood\n",
    "    'CLUSTER',  # socio-economic status\n",
    "    'GENDER',\n",
    "    'MAXADATE', # date of the most recent promotion received\n",
    "    'MINRDATE',\n",
    "    'LASTDATE',\n",
    "    'FISTDATE',\n",
    "    'RFA_2A',\n",
    "]\n",
    "\n",
    "df['ODATEDW'] = df['ODATEDW'].astype('str')\n",
    "df['TCODE'] = df['TCODE'].apply(\n",
    "    lambda x: '{:03d}'.format(x // 1000 if x > 1000 else x))\n",
    "df['ZIP'] = df['ZIP'].str.slice(0, 5)\n",
    "df['MAXADATE'] = df['MAXADATE'].astype('str')\n",
    "df['MINRDATE'] = df['MINRDATE'].astype('str')\n",
    "df['LASTDATE'] = df['LASTDATE'].astype('str')\n",
    "df['FISTDATE'] = df['FISTDATE'].astype('str')\n",
    "\n",
    "\n",
    "def label_encoding(y, frequency_threshold=100):\n",
    "  value_counts = pd.value_counts(y)\n",
    "  categories = value_counts[\n",
    "      value_counts >= frequency_threshold].index.to_numpy()\n",
    "  # 0 indicates the unknown category.\n",
    "  return pd.Categorical(y, categories=categories).codes + 1\n",
    "\n",
    "for key in VOCAB_FEATURES:\n",
    "  df[key] = label_encoding(df[key])\n",
    "\n",
    "MAIL_ORDER_RESPONSES = [\n",
    "    'MBCRAFT',\n",
    "    'MBGARDEN',\n",
    "    'MBBOOKS',\n",
    "    'MBCOLECT',\n",
    "    'MAGFAML',\n",
    "    'MAGFEM',\n",
    "    'MAGMALE',\n",
    "    'PUBGARDN',\n",
    "    'PUBCULIN',\n",
    "    'PUBHLTH',\n",
    "    'PUBDOITY',\n",
    "    'PUBNEWFN',\n",
    "    'PUBPHOTO',\n",
    "    'PUBOPP',\n",
    "    'RFA_2F',\n",
    "]\n",
    "\n",
    "INDICATOR_FEATURES = [\n",
    "    'AGE',  # age decile, 0 indicates unknown\n",
    "    'NUMCHLD',\n",
    "    'INCOME',\n",
    "    'WEALTH1',\n",
    "    'HIT',\n",
    "] + MAIL_ORDER_RESPONSES\n",
    "\n",
    "df['AGE'] = pd.qcut(df['AGE'].values, 10).codes + 1\n",
    "df['NUMCHLD'] = df['NUMCHLD'].apply(lambda x: 0 if np.isnan(x) else int(x))\n",
    "df['INCOME'] = df['INCOME'].apply(lambda x: 0 if np.isnan(x) else int(x))\n",
    "df['WEALTH1'] = df['WEALTH1'].apply(lambda x: 0 if np.isnan(x) else int(x) + 1)\n",
    "df['HIT'] = pd.qcut(df['HIT'].values, q=50, duplicates='drop').codes\n",
    "\n",
    "for col in MAIL_ORDER_RESPONSES:\n",
    "  df[col] = pd.qcut(df[col].values, q=20, duplicates='drop').codes + 1\n",
    "\n",
    "NUMERIC_FEATURES = [\n",
    "    # binary\n",
    "    'MAILCODE',  # bad address\n",
    "    'NOEXCH',    # do not exchange\n",
    "    'RECINHSE',  # donor has given to PVA's in house program\n",
    "    'RECP3',     # donor has given to PVA's P3 program\n",
    "    'RECPGVG',   # planned giving record\n",
    "    'RECSWEEP',  # sweepstakes record\n",
    "    'HOMEOWNR',  # home owner\n",
    "    'CHILD03',\n",
    "    'CHILD07',\n",
    "    'CHILD12',\n",
    "    'CHILD18',\n",
    "\n",
    "    # continuous\n",
    "    'CARDPROM',\n",
    "    'NUMPROM',\n",
    "    'CARDPM12',\n",
    "    'NUMPRM12',\n",
    "    'RAMNTALL',\n",
    "    'NGIFTALL',\n",
    "    'MINRAMNT',\n",
    "    'MAXRAMNT',\n",
    "    'LASTGIFT',\n",
    "    'AVGGIFT',\n",
    "]\n",
    "     \n",
    "\n",
    "df['MAILCODE'] = (df['MAILCODE'] == 'B').astype('float32')\n",
    "df['PVASTATE'] = df['PVASTATE'].isin(['P', 'E']).astype('float32')\n",
    "df['NOEXCH'] = df['NOEXCH'].isin(['X', '1']).astype('float32')\n",
    "df['RECINHSE'] = (df['RECINHSE'] == 'X').astype('float32')\n",
    "df['RECP3'] = (df['RECP3'] == 'X').astype('float32')\n",
    "df['RECPGVG'] = (df['RECPGVG'] == 'X').astype('float32')\n",
    "df['RECSWEEP'] = (df['RECSWEEP'] == 'X').astype('float32')\n",
    "df['HOMEOWNR'] = (df['HOMEOWNR'] == 'H').astype('float32')\n",
    "df['CHILD03'] = df['CHILD03'].isin(['M', 'F', 'B']).astype('float32')\n",
    "df['CHILD07'] = df['CHILD07'].isin(['M', 'F', 'B']).astype('float32')\n",
    "df['CHILD12'] = df['CHILD12'].isin(['M', 'F', 'B']).astype('float32')\n",
    "df['CHILD18'] = df['CHILD18'].isin(['M', 'F', 'B']).astype('float32')\n",
    "\n",
    "df['CARDPROM'] = df['CARDPROM'] / 100\n",
    "df['NUMPROM'] = df['NUMPROM'] / 100\n",
    "df['CARDPM12'] = df['CARDPM12'] / 100\n",
    "df['NUMPRM12'] = df['NUMPRM12'] / 100\n",
    "df['RAMNTALL'] = np.log1p(df['RAMNTALL'])\n",
    "df['NGIFTALL'] = np.log1p(df['NGIFTALL'])\n",
    "df['MINRAMNT'] = np.log1p(df['MINRAMNT'])\n",
    "df['MAXRAMNT'] = np.log1p(df['MAXRAMNT'])\n",
    "df['LASTGIFT'] = np.log1p(df['LASTGIFT'])\n",
    "df['AVGGIFT'] = np.log1p(df['AVGGIFT'])\n",
    "\n",
    "CATEGORICAL_FEATURES = VOCAB_FEATURES + INDICATOR_FEATURES\n",
    "ALL_FEATURES = CATEGORICAL_FEATURES + NUMERIC_FEATURES\n",
    "\n",
    "def dnn_split(df):\n",
    "  df_train = df.iloc[:num_train]\n",
    "  df_eval = df.iloc[num_train:]\n",
    "\n",
    "  def feature_dict(df):\n",
    "    features = {k: v.values.reshape(-1,1) for k, v in dict(df[CATEGORICAL_FEATURES]).items()}\n",
    "    features['numeric'] = df[NUMERIC_FEATURES].astype('float32').values\n",
    "    return features\n",
    "\n",
    "  x_train, y_train = feature_dict(df_train), df_train['TARGET_D'].astype(\n",
    "      'float32').values\n",
    "  x_eval, y_eval = feature_dict(df_eval), df_eval['TARGET_D'].astype(\n",
    "      'float32').values\n",
    "\n",
    "  return x_train, x_eval, y_train, y_eval\n",
    "\n",
    "x_train, x_eval, y_train, y_eval = dnn_split(df)\n",
    "\n",
    "all_data = [{0:[np.hstack(list(x_train.values())),y_train,np.hstack(list(x_eval.values())),y_eval]}]\n",
    "\n",
    "# Diabetes\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "all_data.append({0:[X,y]})\n",
    "\n",
    "\n",
    "# # California housing\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "all_data.append({0:[X.to_numpy(),y.to_numpy()]})\n",
    "\n",
    "\n",
    "# # Liver disorders\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "ld = fetch_openml(name='liver-disorders')\n",
    "\n",
    "\n",
    "\n",
    "X, y = ld['data'].to_numpy(),ld['target'].to_numpy()\n",
    "all_data.append({0:[X,y]})\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "dict_data = {}\n",
    "dict_data[\"Diabetes\"] = {}\n",
    "dict_data[\"California housing\"] = {}\n",
    "dict_data[\"Liver disorders\"] = {}\n",
    "dict_data[\"KDD98\"] = {}\n",
    "\n",
    "for k in all_data[0]:\n",
    "    x01,x02,y01,y02 = all_data[0][k][0], all_data[0][k][2], all_data[0][k][1], all_data[0][k][3]\n",
    "    dict_data[\"KDD98\"][k] = {\"train\":{\"X\":x01,\"y\":y01},\"test\":{\"X\":x02,\"y\":y02}}\n",
    "\n",
    "for k in all_data[0]:\n",
    "    x01,x02,y01,y02 = train_test_split(all_data[0][k][0], all_data[0][k][1], test_size=0.3,random_state=42)\n",
    "    dict_data[\"Diabetes\"][k] = {\"train\":{\"X\":x01,\"y\":y01},\"test\":{\"X\":x02,\"y\":y02}}\n",
    "    \n",
    "# for k in all_data[1]:\n",
    "#     x11,x12,y11,y12 = train_test_split(all_data[1][k][0], all_data[1][k][1],test_size=0.3,random_state=42)\n",
    "#     dict_data[\"California housing\"][k] = {\"train\":{\"X\":x11,\"y\":y11},\"test\":{\"X\":x12,\"y\":y12}} \n",
    "\n",
    "# for k in all_data[2]:\n",
    "#     x11,x12,y11,y12 = train_test_split(all_data[2][k][0], all_data[2][k][1],test_size=0.3,random_state=42)\n",
    "#     dict_data[\"Liver disorders\"][k] = {\"train\":{\"X\":x11,\"y\":y11},\"test\":{\"X\":x12,\"y\":y12}} \n",
    "\n",
    "all_data = dict_data\n",
    "\n",
    "\n",
    "# # Boosting\n",
    "\n",
    "import xgboost as xgb\n",
    "from boosted_forest import CascadeBoostingRegressor\n",
    "from deepforest import CascadeForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "np.bool = np.bool_\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "#xgb.set_config(verbosity=2)\n",
    "\n",
    "def make_modelXGB(max_depth,layers,C):\n",
    "    return xgb.XGBRegressor(max_depth = max_depth, n_estimators = layers)\n",
    "\n",
    "def make_modelCascade(max_depth,layers,C,hs,bs):\n",
    "    return CascadeForestRegressor(max_depth = max_depth, max_layers = layers, n_estimators=10,backend=\"sklearn\",criterion='squared_error')\n",
    "\n",
    "def make_modelBoosted(max_depth,layers,C,hs,bs):\n",
    "    return CascadeBoostingRegressor(C=C, n_layers=layers, n_estimators = 10, max_depth=max_depth, n_iter_no_change = None, validation_fraction = 0.1, learning_rate = 1.0,hidden_size = hs,verbose=1, n_trees=100, batch_size=bs)\n",
    "\n",
    "\n",
    "models = {\"Boosted Forest\": make_modelBoosted,\"Cascade Forest\": make_modelCascade}\n",
    "\n",
    "bo_data = []    \n",
    "\n",
    "for bs in [6000]:\n",
    "    for model_name in models:\n",
    "        make_model = models[model_name]\n",
    "        for ds_name in [\"KDD98\"]:\n",
    "            for depth in all_data[ds_name]:\n",
    "                dat = all_data[ds_name][depth]\n",
    "                x_train = dat[\"train\"][\"X\"]\n",
    "                x_test = dat[\"test\"][\"X\"]\n",
    "                Y_train = dat[\"train\"][\"y\"].flatten()\n",
    "                Y_test = dat[\"test\"][\"y\"].flatten()            \n",
    "\n",
    "                layers = 2\n",
    "                max_depth = 1\n",
    "\n",
    "                C = 100\n",
    "                hs = 10\n",
    "\n",
    "                model = make_model(max_depth,layers,C,hs,bs)\n",
    "                    \n",
    "                model.fit(\n",
    "                    x_train,\n",
    "                    Y_train,\n",
    "                )        \n",
    "                \n",
    "                y_pred = model.predict(x_test) #, batch_size=batch_size)\n",
    "                mse_score = mean_squared_error(Y_test.flatten(),y_pred.flatten())\n",
    "                mae_score = mean_absolute_error(Y_test.flatten(),y_pred.flatten())\n",
    "                print(bs,model_name,ds_name,depth,mse_score, mae_score, Y_test.min(),Y_test.max())     \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2510033-362c-4e47-b5f1-ce81242a2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b2af7-6ac8-4961-8e22-b6cd2321243e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
